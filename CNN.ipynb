{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq-JhCcLpBwS"
      },
      "source": [
        "#Conscientious Cars 2: Convolutional Neural Nets\n",
        "\n",
        "Welcome back to CC: ConscientiousCars! Today, we'll be improving on our system for distinguishing dogs from roads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhNVum16scIW"
      },
      "source": [
        "#@title Run this to load some packages and data! { display-mode: \"form\" }\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, InputLayer\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def categorical_to_numpy(labels_in):\n",
        "  labels = []\n",
        "  for label in labels_in:\n",
        "    if label == 'dog':\n",
        "      labels.append(np.array([1, 0]))\n",
        "    else:\n",
        "      labels.append(np.array([0, 1]))\n",
        "  return np.array(labels)\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  # Run this cell to download our data into a file called 'cifar_data'\n",
        "  import gdown\n",
        "  # gdown.download('https://drive.google.com/uc?id=1-BjeqccJdLiBA6PnNinmXSQ6w5BluLem','cifar_data','True'); # dogs v road;\n",
        "  !wget -O cifar_data https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
        "\n",
        "  # now load the data from our cloud computer\n",
        "  import pickle\n",
        "  data_dict = pickle.load(open( \"cifar_data\", \"rb\" ));\n",
        "  \n",
        "  data   = data_dict['data']\n",
        "  labels = data_dict['labels']\n",
        "  \n",
        "  return data, labels\n",
        "\n",
        "def plot_one_image(data, labels, img_idx):\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  my_img   = data[img_idx, :].squeeze().reshape([32,32,3]).copy()\n",
        "  my_label = labels[img_idx]\n",
        "  print('label: %s'%my_label)\n",
        "  plt.imshow(my_img)\n",
        "  plt.show()\n",
        "  \n",
        "def CNNClassifier(num_epochs=2, layers=1, dropout=0.15):\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((32, 32, 3)))\n",
        "    \n",
        "    for i in range(layers):\n",
        "      model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "      model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "  return KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=10, verbose=2)\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 7)    \n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkseZ14ms7vs"
      },
      "source": [
        "In this notebook, we will:\n",
        "\n",
        "- Use a pre-built CNN function to classify roads vs. dogs.\n",
        "- Build neural networks from scratch in Keras.\n",
        "- Experiment with building CNN models from scratch in Keras.\n",
        "- (Advanced, Optional) Build CNN models for distinguishing cats from dogs, and even experiment with implementing a famous architecture!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWQRlTqt6Yn"
      },
      "source": [
        "**Change Hardware Accelerator to GPU to train faster (Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxGsnvhnn8R"
      },
      "source": [
        "#Loading in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btr24O6Hqgo6"
      },
      "source": [
        "Once again, let's load in our dog/road dataset and create our training and test set. **What's the shape of each dataset? Why?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmZbrZoKnthN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b14af5-e681-4996-8ebf-bfdec32e7f61"
      },
      "source": [
        "# load our data\n",
        "data_raw, labels_raw = load_data()\n",
        "data = data_raw.astype(float)\n",
        "labels = categorical_to_numpy(labels_raw)\n",
        "inputs_train, inputs_test, labels_train, labels_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "#Find the shape of our dataset!\n",
        "### YOUR CODE HERE\n",
        "data.shape\n",
        "#1200 items and in each item 3072 data points\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-10 20:51:49--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3689015 (3.5M) [application/octet-stream]\n",
            "Saving to: ‘cifar_data’\n",
            "\n",
            "\rcifar_data            0%[                    ]       0  --.-KB/s               \rcifar_data          100%[===================>]   3.52M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-06-10 20:51:49 (222 MB/s) - ‘cifar_data’ saved [3689015/3689015]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcZra2S0NNSZ"
      },
      "source": [
        "Use the cell below as a reminder of what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B83F3CmPNSux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "75754f68-c028-455d-e32f-174fa388fa22"
      },
      "source": [
        "plot_one_image(data_raw, labels_raw, 300) # change this number"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: dog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37O_VE_D1Bdy"
      },
      "source": [
        "# Models for Vision: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqrfI4JiVeFr"
      },
      "source": [
        "###Exercise: Exploring Hyperparameters ✍️\n",
        "\n",
        "As you know, there is a famous type of neural network known as convolutional neural networks (CNNs). These types of neural networks work particularly well on problems to do with computer vision. Let's try one out!\n",
        "\n",
        "To load up a simple CNN on scikit-learn, just run:\n",
        "\n",
        "`cnn = CNNClassifier(num_epochs, layers, dropout)`\n",
        "\n",
        "Work with your instructors to review what each parameter means and how it affects the model! The value for **dropout** is a float between 0 and 1 that represents the probability the weight for a neuron in the layer is set to 0 during training time. Each neuron in the layer is evaluated as such, which can help prevent overfitting.\n",
        "\n",
        "**Try different values of num_epochs, layers, and dropout so that you get the best possible accuracy on the test set using `model.score()`**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmC3-T4KRJgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991c3003-8384-4b27-ea32-10f7005b6f33"
      },
      "source": [
        "#dropout PREVENTS OVERFITTING, sets weight to 0 to make sure other weights readjust etc\n",
        "cnn = CNNClassifier(5, 2, 0.5)\n",
        "cnn.fit(inputs_train, labels_train)\n",
        "preds = cnn.predict(inputs_test)\n",
        "print (cnn.score(inputs_test, labels_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "96/96 - 14s - loss: 9.9143 - accuracy: 0.5865 - 14s/epoch - 141ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 1.0492 - accuracy: 0.7198 - 424ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.5559 - accuracy: 0.8125 - 421ms/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.3651 - accuracy: 0.8646 - 416ms/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.3713 - accuracy: 0.8594 - 415ms/epoch - 4ms/step\n",
            "24/24 - 0s - loss: 0.2268 - accuracy: 0.9417 - 369ms/epoch - 15ms/step\n",
            "0.9416666626930237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwghlVU4WTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8239ca-739c-4428-f966-220a48eea30c"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "for x in[1, 3, 5, 7]:\n",
        "  for y in [1, 2, 3]:\n",
        "    for z in [0.25, 0.5, 0.75]:\n",
        "      cnn = CNNClassifier(x, y, z)\n",
        "      cnn.fit(inputs_train, labels_train)\n",
        "      preds = cnn.predict(inputs_test)\n",
        "      print(x, \"epochs\", y, \"layers\", z, \"dropouts\")\n",
        "      print (cnn.score(inputs_test, labels_test))\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 - 1s - loss: 3.9014 - accuracy: 0.6792 - 1s/epoch - 13ms/step\n",
            "1 epochs 1 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.9585 - accuracy: 0.7000 - 193ms/epoch - 8ms/step\n",
            "0.699999988079071\n",
            "96/96 - 1s - loss: 15.8456 - accuracy: 0.5646 - 1s/epoch - 13ms/step\n",
            "1 epochs 1 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 1.0126 - accuracy: 0.7458 - 193ms/epoch - 8ms/step\n",
            "0.7458333373069763\n",
            "96/96 - 1s - loss: 51.0501 - accuracy: 0.5188 - 1s/epoch - 13ms/step\n",
            "1 epochs 1 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 2.0782 - accuracy: 0.5083 - 200ms/epoch - 8ms/step\n",
            "0.5083333253860474\n",
            "96/96 - 1s - loss: 4.4386 - accuracy: 0.6635 - 1s/epoch - 14ms/step\n",
            "1 epochs 2 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 1.1993 - accuracy: 0.6292 - 202ms/epoch - 8ms/step\n",
            "0.6291666626930237\n",
            "96/96 - 1s - loss: 5.4845 - accuracy: 0.6021 - 1s/epoch - 14ms/step\n",
            "1 epochs 2 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.2182 - accuracy: 0.9208 - 206ms/epoch - 9ms/step\n",
            "0.9208333492279053\n",
            "96/96 - 2s - loss: 33.9540 - accuracy: 0.5271 - 2s/epoch - 18ms/step\n",
            "1 epochs 2 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 1.1453 - accuracy: 0.5917 - 211ms/epoch - 9ms/step\n",
            "0.5916666388511658\n",
            "96/96 - 2s - loss: 2.2041 - accuracy: 0.7063 - 2s/epoch - 16ms/step\n",
            "1 epochs 3 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.2251 - accuracy: 0.9000 - 219ms/epoch - 9ms/step\n",
            "0.8999999761581421\n",
            "96/96 - 2s - loss: 2.8063 - accuracy: 0.6187 - 2s/epoch - 16ms/step\n",
            "1 epochs 3 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.3553 - accuracy: 0.8292 - 216ms/epoch - 9ms/step\n",
            "0.8291666507720947\n",
            "96/96 - 1s - loss: 18.8911 - accuracy: 0.5031 - 1s/epoch - 16ms/step\n",
            "1 epochs 3 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.6615 - accuracy: 0.6375 - 224ms/epoch - 9ms/step\n",
            "0.637499988079071\n",
            "Epoch 1/3\n",
            "96/96 - 1s - loss: 5.5088 - accuracy: 0.7000 - 1s/epoch - 13ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 1.2792 - accuracy: 0.8135 - 389ms/epoch - 4ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 0.6448 - accuracy: 0.8635 - 400ms/epoch - 4ms/step\n",
            "3 epochs 1 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.5008 - accuracy: 0.8167 - 197ms/epoch - 8ms/step\n",
            "0.8166666626930237\n",
            "Epoch 1/3\n",
            "96/96 - 1s - loss: 13.1337 - accuracy: 0.6146 - 1s/epoch - 13ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 2.3246 - accuracy: 0.7594 - 394ms/epoch - 4ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 0.9007 - accuracy: 0.8052 - 388ms/epoch - 4ms/step\n",
            "3 epochs 1 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1818 - accuracy: 0.9375 - 218ms/epoch - 9ms/step\n",
            "0.9375\n",
            "Epoch 1/3\n",
            "96/96 - 2s - loss: 36.3481 - accuracy: 0.5146 - 2s/epoch - 16ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 10.2337 - accuracy: 0.5219 - 399ms/epoch - 4ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 3.4906 - accuracy: 0.5667 - 408ms/epoch - 4ms/step\n",
            "3 epochs 1 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.4509 - accuracy: 0.8250 - 202ms/epoch - 8ms/step\n",
            "0.824999988079071\n",
            "Epoch 1/3\n",
            "96/96 - 1s - loss: 3.0323 - accuracy: 0.6573 - 1s/epoch - 15ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 0.5246 - accuracy: 0.8385 - 436ms/epoch - 5ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 0.2949 - accuracy: 0.8865 - 445ms/epoch - 5ms/step\n",
            "3 epochs 2 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.2244 - accuracy: 0.8958 - 203ms/epoch - 8ms/step\n",
            "0.8958333134651184\n",
            "Epoch 1/3\n",
            "96/96 - 1s - loss: 18.1799 - accuracy: 0.5646 - 1s/epoch - 14ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 2.7809 - accuracy: 0.6885 - 428ms/epoch - 4ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 0.9657 - accuracy: 0.7740 - 431ms/epoch - 4ms/step\n",
            "3 epochs 2 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1846 - accuracy: 0.9250 - 206ms/epoch - 9ms/step\n",
            "0.925000011920929\n",
            "Epoch 1/3\n",
            "96/96 - 1s - loss: 10.5512 - accuracy: 0.5240 - 1s/epoch - 14ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 3.1812 - accuracy: 0.5427 - 432ms/epoch - 4ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 1.4176 - accuracy: 0.5854 - 421ms/epoch - 4ms/step\n",
            "3 epochs 2 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.4719 - accuracy: 0.8625 - 204ms/epoch - 8ms/step\n",
            "0.862500011920929\n",
            "Epoch 1/3\n",
            "96/96 - 1s - loss: 1.9487 - accuracy: 0.7052 - 1s/epoch - 16ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 0.3416 - accuracy: 0.8760 - 460ms/epoch - 5ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 0.2266 - accuracy: 0.9104 - 460ms/epoch - 5ms/step\n",
            "3 epochs 3 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.1586 - accuracy: 0.9458 - 212ms/epoch - 9ms/step\n",
            "0.9458333253860474\n",
            "Epoch 1/3\n",
            "96/96 - 2s - loss: 3.4177 - accuracy: 0.6031 - 2s/epoch - 19ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 0.7784 - accuracy: 0.7448 - 458ms/epoch - 5ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 0.4586 - accuracy: 0.8167 - 485ms/epoch - 5ms/step\n",
            "3 epochs 3 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.2620 - accuracy: 0.9167 - 220ms/epoch - 9ms/step\n",
            "0.9166666865348816\n",
            "Epoch 1/3\n",
            "96/96 - 2s - loss: 16.4772 - accuracy: 0.5125 - 2s/epoch - 16ms/step\n",
            "Epoch 2/3\n",
            "96/96 - 0s - loss: 2.5869 - accuracy: 0.5094 - 461ms/epoch - 5ms/step\n",
            "Epoch 3/3\n",
            "96/96 - 0s - loss: 1.1184 - accuracy: 0.5396 - 474ms/epoch - 5ms/step\n",
            "3 epochs 3 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.5931 - accuracy: 0.8042 - 211ms/epoch - 9ms/step\n",
            "0.8041666746139526\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 6.2375 - accuracy: 0.6750 - 1s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 1.2211 - accuracy: 0.8177 - 383ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.5313 - accuracy: 0.8781 - 392ms/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.3562 - accuracy: 0.8990 - 398ms/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.2897 - accuracy: 0.9062 - 383ms/epoch - 4ms/step\n",
            "5 epochs 1 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.1669 - accuracy: 0.9250 - 204ms/epoch - 8ms/step\n",
            "0.925000011920929\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 8.4913 - accuracy: 0.5646 - 1s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 1.6448 - accuracy: 0.7625 - 392ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.7568 - accuracy: 0.8229 - 403ms/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.4468 - accuracy: 0.8573 - 393ms/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.3427 - accuracy: 0.8740 - 406ms/epoch - 4ms/step\n",
            "5 epochs 1 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1773 - accuracy: 0.9375 - 195ms/epoch - 8ms/step\n",
            "0.9375\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 37.9447 - accuracy: 0.5302 - 1s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 7.2396 - accuracy: 0.5615 - 404ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 2.2693 - accuracy: 0.5667 - 378ms/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 1.0932 - accuracy: 0.6125 - 377ms/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.7598 - accuracy: 0.6917 - 407ms/epoch - 4ms/step\n",
            "5 epochs 1 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.5081 - accuracy: 0.8250 - 194ms/epoch - 8ms/step\n",
            "0.824999988079071\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 4.6830 - accuracy: 0.6885 - 1s/epoch - 14ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 0.6490 - accuracy: 0.8167 - 427ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.3166 - accuracy: 0.8896 - 435ms/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.2485 - accuracy: 0.9052 - 438ms/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.2067 - accuracy: 0.9167 - 440ms/epoch - 5ms/step\n",
            "5 epochs 2 layers 0.25 dropouts\n",
            "24/24 - 1s - loss: 0.1889 - accuracy: 0.9292 - 503ms/epoch - 21ms/step\n",
            "0.9291666746139526\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 6.2472 - accuracy: 0.6135 - 1s/epoch - 15ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 1.1741 - accuracy: 0.7510 - 425ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.6605 - accuracy: 0.8094 - 439ms/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.4481 - accuracy: 0.8604 - 435ms/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.3394 - accuracy: 0.8615 - 431ms/epoch - 4ms/step\n",
            "5 epochs 2 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1591 - accuracy: 0.9542 - 212ms/epoch - 9ms/step\n",
            "0.9541666507720947\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 18.0713 - accuracy: 0.4844 - 1s/epoch - 14ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 2.4503 - accuracy: 0.5688 - 432ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.8729 - accuracy: 0.6573 - 419ms/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.5298 - accuracy: 0.7615 - 427ms/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.4238 - accuracy: 0.8365 - 428ms/epoch - 4ms/step\n",
            "5 epochs 2 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.3973 - accuracy: 0.8083 - 216ms/epoch - 9ms/step\n",
            "0.8083333373069763\n",
            "Epoch 1/5\n",
            "96/96 - 2s - loss: 2.3932 - accuracy: 0.6802 - 2s/epoch - 16ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 0.4775 - accuracy: 0.8448 - 467ms/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.2767 - accuracy: 0.8958 - 463ms/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.2449 - accuracy: 0.9125 - 466ms/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.1925 - accuracy: 0.9302 - 463ms/epoch - 5ms/step\n",
            "5 epochs 3 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.2500 - accuracy: 0.9042 - 220ms/epoch - 9ms/step\n",
            "0.9041666388511658\n",
            "Epoch 1/5\n",
            "96/96 - 2s - loss: 4.7038 - accuracy: 0.5698 - 2s/epoch - 16ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 0.9572 - accuracy: 0.6990 - 470ms/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.4653 - accuracy: 0.8125 - 464ms/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.3424 - accuracy: 0.8542 - 465ms/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.2600 - accuracy: 0.8906 - 460ms/epoch - 5ms/step\n",
            "5 epochs 3 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1675 - accuracy: 0.9458 - 222ms/epoch - 9ms/step\n",
            "0.9458333253860474\n",
            "Epoch 1/5\n",
            "96/96 - 1s - loss: 27.1849 - accuracy: 0.5042 - 1s/epoch - 16ms/step\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 2.5017 - accuracy: 0.5625 - 460ms/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.9680 - accuracy: 0.5917 - 475ms/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.6194 - accuracy: 0.7156 - 464ms/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.4727 - accuracy: 0.7823 - 458ms/epoch - 5ms/step\n",
            "5 epochs 3 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.3700 - accuracy: 0.9167 - 213ms/epoch - 9ms/step\n",
            "0.9166666865348816\n",
            "Epoch 1/7\n",
            "96/96 - 2s - loss: 5.3813 - accuracy: 0.6938 - 2s/epoch - 17ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 1.1509 - accuracy: 0.8167 - 397ms/epoch - 4ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 0.6094 - accuracy: 0.8667 - 387ms/epoch - 4ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.3452 - accuracy: 0.9052 - 412ms/epoch - 4ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.2548 - accuracy: 0.9219 - 393ms/epoch - 4ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.2208 - accuracy: 0.9260 - 390ms/epoch - 4ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.1470 - accuracy: 0.9521 - 395ms/epoch - 4ms/step\n",
            "7 epochs 1 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.1652 - accuracy: 0.9458 - 203ms/epoch - 8ms/step\n",
            "0.9458333253860474\n",
            "Epoch 1/7\n",
            "96/96 - 1s - loss: 11.0953 - accuracy: 0.6052 - 1s/epoch - 14ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 1.6722 - accuracy: 0.7583 - 383ms/epoch - 4ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 0.5909 - accuracy: 0.8490 - 389ms/epoch - 4ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.4812 - accuracy: 0.8583 - 404ms/epoch - 4ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.3925 - accuracy: 0.8781 - 393ms/epoch - 4ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.3012 - accuracy: 0.9062 - 399ms/epoch - 4ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.2593 - accuracy: 0.9052 - 391ms/epoch - 4ms/step\n",
            "7 epochs 1 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1580 - accuracy: 0.9375 - 194ms/epoch - 8ms/step\n",
            "0.9375\n",
            "Epoch 1/7\n",
            "96/96 - 1s - loss: 75.6556 - accuracy: 0.5094 - 1s/epoch - 13ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 20.0260 - accuracy: 0.5260 - 388ms/epoch - 4ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 6.6760 - accuracy: 0.5146 - 380ms/epoch - 4ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 2.5482 - accuracy: 0.5990 - 391ms/epoch - 4ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 1.3644 - accuracy: 0.5896 - 391ms/epoch - 4ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 1s - loss: 0.8542 - accuracy: 0.6542 - 651ms/epoch - 7ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 1s - loss: 0.7328 - accuracy: 0.6802 - 525ms/epoch - 5ms/step\n",
            "7 epochs 1 layers 0.75 dropouts\n",
            "24/24 - 1s - loss: 0.5044 - accuracy: 0.8208 - 575ms/epoch - 24ms/step\n",
            "0.8208333253860474\n",
            "Epoch 1/7\n",
            "96/96 - 1s - loss: 1.4744 - accuracy: 0.7448 - 1s/epoch - 15ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 0.4041 - accuracy: 0.8792 - 429ms/epoch - 4ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 0.2848 - accuracy: 0.9052 - 436ms/epoch - 5ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.2190 - accuracy: 0.9240 - 442ms/epoch - 5ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.1603 - accuracy: 0.9406 - 429ms/epoch - 4ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.1318 - accuracy: 0.9531 - 433ms/epoch - 5ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.1333 - accuracy: 0.9573 - 424ms/epoch - 4ms/step\n",
            "7 epochs 2 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.1388 - accuracy: 0.9625 - 209ms/epoch - 9ms/step\n",
            "0.9624999761581421\n",
            "Epoch 1/7\n",
            "96/96 - 1s - loss: 5.3760 - accuracy: 0.6187 - 1s/epoch - 14ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 0.9277 - accuracy: 0.7646 - 430ms/epoch - 4ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 0.5023 - accuracy: 0.8479 - 428ms/epoch - 4ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.3522 - accuracy: 0.8625 - 428ms/epoch - 4ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.3027 - accuracy: 0.8906 - 437ms/epoch - 5ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.2971 - accuracy: 0.9000 - 427ms/epoch - 4ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.2386 - accuracy: 0.9167 - 452ms/epoch - 5ms/step\n",
            "7 epochs 2 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1377 - accuracy: 0.9500 - 199ms/epoch - 8ms/step\n",
            "0.949999988079071\n",
            "Epoch 1/7\n",
            "96/96 - 1s - loss: 26.1651 - accuracy: 0.5094 - 1s/epoch - 14ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 5.7700 - accuracy: 0.5104 - 422ms/epoch - 4ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 1.9406 - accuracy: 0.5740 - 418ms/epoch - 4ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.9836 - accuracy: 0.6417 - 429ms/epoch - 4ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.6555 - accuracy: 0.6885 - 420ms/epoch - 4ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.5248 - accuracy: 0.7708 - 431ms/epoch - 4ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.4337 - accuracy: 0.8104 - 419ms/epoch - 4ms/step\n",
            "7 epochs 2 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.2778 - accuracy: 0.9333 - 201ms/epoch - 8ms/step\n",
            "0.9333333373069763\n",
            "Epoch 1/7\n",
            "96/96 - 2s - loss: 1.3726 - accuracy: 0.7396 - 2s/epoch - 16ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 0.3378 - accuracy: 0.8813 - 463ms/epoch - 5ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 0.2523 - accuracy: 0.9052 - 454ms/epoch - 5ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.2149 - accuracy: 0.9260 - 468ms/epoch - 5ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.1644 - accuracy: 0.9417 - 472ms/epoch - 5ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.1574 - accuracy: 0.9417 - 464ms/epoch - 5ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.1507 - accuracy: 0.9438 - 467ms/epoch - 5ms/step\n",
            "7 epochs 3 layers 0.25 dropouts\n",
            "24/24 - 0s - loss: 0.1424 - accuracy: 0.9292 - 226ms/epoch - 9ms/step\n",
            "0.9291666746139526\n",
            "Epoch 1/7\n",
            "96/96 - 2s - loss: 2.1393 - accuracy: 0.6583 - 2s/epoch - 16ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 0.5160 - accuracy: 0.8031 - 469ms/epoch - 5ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 0.3462 - accuracy: 0.8604 - 476ms/epoch - 5ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.2793 - accuracy: 0.8875 - 476ms/epoch - 5ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.2395 - accuracy: 0.9052 - 496ms/epoch - 5ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 1s - loss: 0.2508 - accuracy: 0.9115 - 546ms/epoch - 6ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 1s - loss: 0.2207 - accuracy: 0.9167 - 668ms/epoch - 7ms/step\n",
            "7 epochs 3 layers 0.5 dropouts\n",
            "24/24 - 0s - loss: 0.1896 - accuracy: 0.9417 - 317ms/epoch - 13ms/step\n",
            "0.9416666626930237\n",
            "Epoch 1/7\n",
            "96/96 - 2s - loss: 13.1842 - accuracy: 0.5010 - 2s/epoch - 16ms/step\n",
            "Epoch 2/7\n",
            "96/96 - 0s - loss: 2.6381 - accuracy: 0.5500 - 465ms/epoch - 5ms/step\n",
            "Epoch 3/7\n",
            "96/96 - 0s - loss: 1.1003 - accuracy: 0.5938 - 469ms/epoch - 5ms/step\n",
            "Epoch 4/7\n",
            "96/96 - 0s - loss: 0.6418 - accuracy: 0.7104 - 469ms/epoch - 5ms/step\n",
            "Epoch 5/7\n",
            "96/96 - 0s - loss: 0.4532 - accuracy: 0.8000 - 470ms/epoch - 5ms/step\n",
            "Epoch 6/7\n",
            "96/96 - 0s - loss: 0.4255 - accuracy: 0.8260 - 457ms/epoch - 5ms/step\n",
            "Epoch 7/7\n",
            "96/96 - 0s - loss: 0.3482 - accuracy: 0.8531 - 469ms/epoch - 5ms/step\n",
            "7 epochs 3 layers 0.75 dropouts\n",
            "24/24 - 0s - loss: 0.3207 - accuracy: 0.9083 - 211ms/epoch - 9ms/step\n",
            "0.9083333611488342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWpgsVXP1ut"
      },
      "source": [
        "**How well did your neural network perform?** \n",
        "\n",
        "CNNs typically perform better than fully-connected neural networks on vision problems, but, as before, they aren't always consistent. They are also sensitive to a number of parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XRh5Y5P_CL"
      },
      "source": [
        "## Training and Validation Curves\n",
        "\n",
        "An important aspect of training neural networks is to prevent overfitting. **How would we recognize overfitting?**\n",
        "\n",
        "In the first line of code below, we first **fit** the model on the training data and pass in some validation (or test) data to evaluate it. We call it the **history** because we want to retain information about the accuracy at each epoch.\n",
        "\n",
        "In the second line we plot the history so that we can compare the training and validation accuracies.  \n",
        "\n",
        "```\n",
        "history = model.fit(inputs_train, labels_train, validation_data=(inputs_test, labels_test))\n",
        "plot_acc(history)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eaFvE2PQEFe"
      },
      "source": [
        "###Exercise: Plotting a Training vs. Validation Curve For Our CNN ✍️\n",
        "\n",
        "**After how many epochs does the model begin to overfit? How does this vary as you vary the number of hidden layers and dropout?** Overfitting occurs when the validation accuracy starts to drop below the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsVAasDbjARJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0397495-3bfe-411f-bb82-139c3e541d01"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "cnn = CNNClassifier(80, 2, 0.5)\n",
        "history = cnn.fit(inputs_train, labels_train, validation_data=(inputs_test, labels_test))\n",
        "plot_acc(history)\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 - 2s - loss: 10.2814 - accuracy: 0.6250 - val_loss: 0.2631 - val_accuracy: 0.9042 - 2s/epoch - 25ms/step\n",
            "Epoch 2/80\n",
            "96/96 - 1s - loss: 1.3930 - accuracy: 0.7677 - val_loss: 0.7150 - val_accuracy: 0.7708 - 505ms/epoch - 5ms/step\n",
            "Epoch 3/80\n",
            "96/96 - 0s - loss: 0.5203 - accuracy: 0.8458 - val_loss: 0.1746 - val_accuracy: 0.9292 - 496ms/epoch - 5ms/step\n",
            "Epoch 4/80\n",
            "96/96 - 0s - loss: 0.3298 - accuracy: 0.8833 - val_loss: 0.1721 - val_accuracy: 0.9292 - 500ms/epoch - 5ms/step\n",
            "Epoch 5/80\n",
            "96/96 - 0s - loss: 0.2577 - accuracy: 0.9031 - val_loss: 0.1612 - val_accuracy: 0.9292 - 492ms/epoch - 5ms/step\n",
            "Epoch 6/80\n",
            "96/96 - 0s - loss: 0.2579 - accuracy: 0.9052 - val_loss: 0.1496 - val_accuracy: 0.9417 - 499ms/epoch - 5ms/step\n",
            "Epoch 7/80\n",
            "96/96 - 0s - loss: 0.2072 - accuracy: 0.9354 - val_loss: 0.1367 - val_accuracy: 0.9542 - 492ms/epoch - 5ms/step\n",
            "Epoch 8/80\n",
            "96/96 - 1s - loss: 0.2190 - accuracy: 0.9094 - val_loss: 0.1307 - val_accuracy: 0.9458 - 508ms/epoch - 5ms/step\n",
            "Epoch 9/80\n",
            "96/96 - 0s - loss: 0.2069 - accuracy: 0.9260 - val_loss: 0.1331 - val_accuracy: 0.9500 - 479ms/epoch - 5ms/step\n",
            "Epoch 10/80\n",
            "96/96 - 0s - loss: 0.1967 - accuracy: 0.9385 - val_loss: 0.1318 - val_accuracy: 0.9542 - 498ms/epoch - 5ms/step\n",
            "Epoch 11/80\n",
            "96/96 - 0s - loss: 0.2069 - accuracy: 0.9354 - val_loss: 0.1327 - val_accuracy: 0.9333 - 490ms/epoch - 5ms/step\n",
            "Epoch 12/80\n",
            "96/96 - 1s - loss: 0.1299 - accuracy: 0.9500 - val_loss: 0.1361 - val_accuracy: 0.9625 - 503ms/epoch - 5ms/step\n",
            "Epoch 13/80\n",
            "96/96 - 0s - loss: 0.1570 - accuracy: 0.9563 - val_loss: 0.1890 - val_accuracy: 0.9417 - 482ms/epoch - 5ms/step\n",
            "Epoch 14/80\n",
            "96/96 - 0s - loss: 0.1448 - accuracy: 0.9448 - val_loss: 0.2382 - val_accuracy: 0.9292 - 497ms/epoch - 5ms/step\n",
            "Epoch 15/80\n",
            "96/96 - 1s - loss: 0.1550 - accuracy: 0.9500 - val_loss: 0.1386 - val_accuracy: 0.9583 - 509ms/epoch - 5ms/step\n",
            "Epoch 16/80\n",
            "96/96 - 0s - loss: 0.1572 - accuracy: 0.9542 - val_loss: 0.1375 - val_accuracy: 0.9542 - 497ms/epoch - 5ms/step\n",
            "Epoch 17/80\n",
            "96/96 - 0s - loss: 0.1457 - accuracy: 0.9479 - val_loss: 0.2650 - val_accuracy: 0.9167 - 494ms/epoch - 5ms/step\n",
            "Epoch 18/80\n",
            "96/96 - 0s - loss: 0.1420 - accuracy: 0.9479 - val_loss: 0.1739 - val_accuracy: 0.9500 - 500ms/epoch - 5ms/step\n",
            "Epoch 19/80\n",
            "96/96 - 0s - loss: 0.1193 - accuracy: 0.9625 - val_loss: 0.1394 - val_accuracy: 0.9583 - 490ms/epoch - 5ms/step\n",
            "Epoch 20/80\n",
            "96/96 - 1s - loss: 0.1316 - accuracy: 0.9604 - val_loss: 0.1282 - val_accuracy: 0.9708 - 506ms/epoch - 5ms/step\n",
            "Epoch 21/80\n",
            "96/96 - 1s - loss: 0.1360 - accuracy: 0.9656 - val_loss: 0.1506 - val_accuracy: 0.9542 - 531ms/epoch - 6ms/step\n",
            "Epoch 22/80\n",
            "96/96 - 1s - loss: 0.0906 - accuracy: 0.9719 - val_loss: 0.1366 - val_accuracy: 0.9708 - 505ms/epoch - 5ms/step\n",
            "Epoch 23/80\n",
            "96/96 - 1s - loss: 0.1417 - accuracy: 0.9625 - val_loss: 0.1115 - val_accuracy: 0.9667 - 501ms/epoch - 5ms/step\n",
            "Epoch 24/80\n",
            "96/96 - 1s - loss: 0.0968 - accuracy: 0.9719 - val_loss: 0.1419 - val_accuracy: 0.9583 - 507ms/epoch - 5ms/step\n",
            "Epoch 25/80\n",
            "96/96 - 0s - loss: 0.1600 - accuracy: 0.9594 - val_loss: 0.1392 - val_accuracy: 0.9625 - 498ms/epoch - 5ms/step\n",
            "Epoch 26/80\n",
            "96/96 - 0s - loss: 0.1423 - accuracy: 0.9573 - val_loss: 0.1297 - val_accuracy: 0.9667 - 489ms/epoch - 5ms/step\n",
            "Epoch 27/80\n",
            "96/96 - 0s - loss: 0.0948 - accuracy: 0.9635 - val_loss: 0.1187 - val_accuracy: 0.9667 - 494ms/epoch - 5ms/step\n",
            "Epoch 28/80\n",
            "96/96 - 1s - loss: 0.1325 - accuracy: 0.9625 - val_loss: 0.1148 - val_accuracy: 0.9833 - 502ms/epoch - 5ms/step\n",
            "Epoch 29/80\n",
            "96/96 - 0s - loss: 0.1126 - accuracy: 0.9594 - val_loss: 0.1397 - val_accuracy: 0.9625 - 498ms/epoch - 5ms/step\n",
            "Epoch 30/80\n",
            "96/96 - 0s - loss: 0.0852 - accuracy: 0.9667 - val_loss: 0.1202 - val_accuracy: 0.9792 - 500ms/epoch - 5ms/step\n",
            "Epoch 31/80\n",
            "96/96 - 1s - loss: 0.0893 - accuracy: 0.9677 - val_loss: 0.1827 - val_accuracy: 0.9458 - 505ms/epoch - 5ms/step\n",
            "Epoch 32/80\n",
            "96/96 - 1s - loss: 0.1173 - accuracy: 0.9635 - val_loss: 0.1161 - val_accuracy: 0.9750 - 506ms/epoch - 5ms/step\n",
            "Epoch 33/80\n",
            "96/96 - 1s - loss: 0.1002 - accuracy: 0.9604 - val_loss: 0.1140 - val_accuracy: 0.9708 - 513ms/epoch - 5ms/step\n",
            "Epoch 34/80\n",
            "96/96 - 1s - loss: 0.1042 - accuracy: 0.9708 - val_loss: 0.1103 - val_accuracy: 0.9792 - 529ms/epoch - 6ms/step\n",
            "Epoch 35/80\n",
            "96/96 - 0s - loss: 0.1206 - accuracy: 0.9583 - val_loss: 0.1291 - val_accuracy: 0.9625 - 495ms/epoch - 5ms/step\n",
            "Epoch 36/80\n",
            "96/96 - 0s - loss: 0.1103 - accuracy: 0.9698 - val_loss: 0.1968 - val_accuracy: 0.9417 - 494ms/epoch - 5ms/step\n",
            "Epoch 37/80\n",
            "96/96 - 0s - loss: 0.1024 - accuracy: 0.9688 - val_loss: 0.1357 - val_accuracy: 0.9625 - 490ms/epoch - 5ms/step\n",
            "Epoch 38/80\n",
            "96/96 - 1s - loss: 0.0988 - accuracy: 0.9625 - val_loss: 0.1324 - val_accuracy: 0.9667 - 507ms/epoch - 5ms/step\n",
            "Epoch 39/80\n",
            "96/96 - 0s - loss: 0.0914 - accuracy: 0.9688 - val_loss: 0.0993 - val_accuracy: 0.9750 - 492ms/epoch - 5ms/step\n",
            "Epoch 40/80\n",
            "96/96 - 1s - loss: 0.1152 - accuracy: 0.9635 - val_loss: 0.1571 - val_accuracy: 0.9667 - 502ms/epoch - 5ms/step\n",
            "Epoch 41/80\n",
            "96/96 - 1s - loss: 0.1056 - accuracy: 0.9698 - val_loss: 0.2232 - val_accuracy: 0.9375 - 506ms/epoch - 5ms/step\n",
            "Epoch 42/80\n",
            "96/96 - 0s - loss: 0.1067 - accuracy: 0.9677 - val_loss: 0.1264 - val_accuracy: 0.9750 - 494ms/epoch - 5ms/step\n",
            "Epoch 43/80\n",
            "96/96 - 1s - loss: 0.0963 - accuracy: 0.9812 - val_loss: 0.1196 - val_accuracy: 0.9833 - 504ms/epoch - 5ms/step\n",
            "Epoch 44/80\n",
            "96/96 - 1s - loss: 0.0719 - accuracy: 0.9771 - val_loss: 0.1761 - val_accuracy: 0.9583 - 509ms/epoch - 5ms/step\n",
            "Epoch 45/80\n",
            "96/96 - 0s - loss: 0.1025 - accuracy: 0.9708 - val_loss: 0.2242 - val_accuracy: 0.9542 - 496ms/epoch - 5ms/step\n",
            "Epoch 46/80\n",
            "96/96 - 1s - loss: 0.1033 - accuracy: 0.9719 - val_loss: 0.1880 - val_accuracy: 0.9500 - 509ms/epoch - 5ms/step\n",
            "Epoch 47/80\n",
            "96/96 - 0s - loss: 0.0902 - accuracy: 0.9719 - val_loss: 0.1248 - val_accuracy: 0.9625 - 495ms/epoch - 5ms/step\n",
            "Epoch 48/80\n",
            "96/96 - 0s - loss: 0.0868 - accuracy: 0.9740 - val_loss: 0.2436 - val_accuracy: 0.9417 - 497ms/epoch - 5ms/step\n",
            "Epoch 49/80\n",
            "96/96 - 0s - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.1035 - val_accuracy: 0.9667 - 496ms/epoch - 5ms/step\n",
            "Epoch 50/80\n",
            "96/96 - 1s - loss: 0.0985 - accuracy: 0.9740 - val_loss: 0.1297 - val_accuracy: 0.9667 - 511ms/epoch - 5ms/step\n",
            "Epoch 51/80\n",
            "96/96 - 0s - loss: 0.1143 - accuracy: 0.9688 - val_loss: 0.1293 - val_accuracy: 0.9750 - 496ms/epoch - 5ms/step\n",
            "Epoch 52/80\n",
            "96/96 - 1s - loss: 0.0756 - accuracy: 0.9812 - val_loss: 0.1307 - val_accuracy: 0.9750 - 507ms/epoch - 5ms/step\n",
            "Epoch 53/80\n",
            "96/96 - 0s - loss: 0.0728 - accuracy: 0.9740 - val_loss: 0.1085 - val_accuracy: 0.9792 - 495ms/epoch - 5ms/step\n",
            "Epoch 54/80\n",
            "96/96 - 1s - loss: 0.0857 - accuracy: 0.9792 - val_loss: 0.1576 - val_accuracy: 0.9583 - 507ms/epoch - 5ms/step\n",
            "Epoch 55/80\n",
            "96/96 - 0s - loss: 0.1142 - accuracy: 0.9708 - val_loss: 0.1214 - val_accuracy: 0.9667 - 493ms/epoch - 5ms/step\n",
            "Epoch 56/80\n",
            "96/96 - 0s - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.1552 - val_accuracy: 0.9583 - 493ms/epoch - 5ms/step\n",
            "Epoch 57/80\n",
            "96/96 - 0s - loss: 0.0999 - accuracy: 0.9719 - val_loss: 0.1186 - val_accuracy: 0.9708 - 500ms/epoch - 5ms/step\n",
            "Epoch 58/80\n",
            "96/96 - 1s - loss: 0.0489 - accuracy: 0.9802 - val_loss: 0.1192 - val_accuracy: 0.9792 - 510ms/epoch - 5ms/step\n",
            "Epoch 59/80\n",
            "96/96 - 0s - loss: 0.0859 - accuracy: 0.9760 - val_loss: 0.1794 - val_accuracy: 0.9500 - 495ms/epoch - 5ms/step\n",
            "Epoch 60/80\n",
            "96/96 - 1s - loss: 0.0802 - accuracy: 0.9760 - val_loss: 0.1301 - val_accuracy: 0.9708 - 508ms/epoch - 5ms/step\n",
            "Epoch 61/80\n",
            "96/96 - 1s - loss: 0.0962 - accuracy: 0.9771 - val_loss: 0.1467 - val_accuracy: 0.9542 - 518ms/epoch - 5ms/step\n",
            "Epoch 62/80\n",
            "96/96 - 1s - loss: 0.0680 - accuracy: 0.9823 - val_loss: 0.1421 - val_accuracy: 0.9667 - 503ms/epoch - 5ms/step\n",
            "Epoch 63/80\n",
            "96/96 - 0s - loss: 0.0982 - accuracy: 0.9688 - val_loss: 0.1426 - val_accuracy: 0.9667 - 498ms/epoch - 5ms/step\n",
            "Epoch 64/80\n",
            "96/96 - 0s - loss: 0.0620 - accuracy: 0.9833 - val_loss: 0.1334 - val_accuracy: 0.9708 - 496ms/epoch - 5ms/step\n",
            "Epoch 65/80\n",
            "96/96 - 0s - loss: 0.0792 - accuracy: 0.9802 - val_loss: 0.1486 - val_accuracy: 0.9625 - 484ms/epoch - 5ms/step\n",
            "Epoch 66/80\n",
            "96/96 - 1s - loss: 0.0865 - accuracy: 0.9719 - val_loss: 0.1388 - val_accuracy: 0.9708 - 502ms/epoch - 5ms/step\n",
            "Epoch 67/80\n",
            "96/96 - 1s - loss: 0.0824 - accuracy: 0.9750 - val_loss: 0.1321 - val_accuracy: 0.9667 - 502ms/epoch - 5ms/step\n",
            "Epoch 68/80\n",
            "96/96 - 1s - loss: 0.0689 - accuracy: 0.9792 - val_loss: 0.1647 - val_accuracy: 0.9625 - 502ms/epoch - 5ms/step\n",
            "Epoch 69/80\n",
            "96/96 - 1s - loss: 0.0787 - accuracy: 0.9708 - val_loss: 0.2688 - val_accuracy: 0.9458 - 502ms/epoch - 5ms/step\n",
            "Epoch 70/80\n",
            "96/96 - 1s - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.1468 - val_accuracy: 0.9667 - 509ms/epoch - 5ms/step\n",
            "Epoch 71/80\n",
            "96/96 - 1s - loss: 0.0744 - accuracy: 0.9792 - val_loss: 0.1290 - val_accuracy: 0.9708 - 526ms/epoch - 5ms/step\n",
            "Epoch 72/80\n",
            "96/96 - 1s - loss: 0.1145 - accuracy: 0.9760 - val_loss: 0.1688 - val_accuracy: 0.9667 - 503ms/epoch - 5ms/step\n",
            "Epoch 73/80\n",
            "96/96 - 1s - loss: 0.0747 - accuracy: 0.9802 - val_loss: 0.1573 - val_accuracy: 0.9583 - 503ms/epoch - 5ms/step\n",
            "Epoch 74/80\n",
            "96/96 - 1s - loss: 0.1110 - accuracy: 0.9781 - val_loss: 0.1131 - val_accuracy: 0.9708 - 531ms/epoch - 6ms/step\n",
            "Epoch 75/80\n",
            "96/96 - 0s - loss: 0.0891 - accuracy: 0.9708 - val_loss: 0.1212 - val_accuracy: 0.9667 - 494ms/epoch - 5ms/step\n",
            "Epoch 76/80\n",
            "96/96 - 1s - loss: 0.0730 - accuracy: 0.9802 - val_loss: 0.1539 - val_accuracy: 0.9708 - 508ms/epoch - 5ms/step\n",
            "Epoch 77/80\n",
            "96/96 - 1s - loss: 0.0745 - accuracy: 0.9802 - val_loss: 0.1377 - val_accuracy: 0.9625 - 504ms/epoch - 5ms/step\n",
            "Epoch 78/80\n",
            "96/96 - 1s - loss: 0.0687 - accuracy: 0.9833 - val_loss: 0.1672 - val_accuracy: 0.9583 - 523ms/epoch - 5ms/step\n",
            "Epoch 79/80\n",
            "96/96 - 1s - loss: 0.0801 - accuracy: 0.9792 - val_loss: 0.1372 - val_accuracy: 0.9667 - 515ms/epoch - 5ms/step\n",
            "Epoch 80/80\n",
            "96/96 - 1s - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.1516 - val_accuracy: 0.9667 - 510ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76z4NAY6afd7"
      },
      "source": [
        "# Building Neural Networks from Scratch in Keras \n",
        "\n",
        "So far, we've used helper functions which pre-build Keras neural network models. Now, we will build them on our own!\n",
        "\n",
        "Let's start with a \"toy example\": a tiny neural network with just three numerical inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdngkAX_aCVu"
      },
      "source": [
        "###Exercise: Building a Simple Neural Network using Keras! ✍️\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-Pt3wGCXRu"
      },
      "source": [
        "\n",
        "We're going to build this model: \n",
        "\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-6WGeedvTCS"
      },
      "source": [
        "This network can be described as: \n",
        "* Input Layer: 3 neurons\n",
        "* Layer 1 (Hidden): 4 neurons that are activated by `'relu'`\n",
        "* Layer 2 (Output): 2 neurons that are activated by `'softmax'`\n",
        "\n",
        "\n",
        "We also want to compile the model with\n",
        "`loss = 'categorical_crossentropy'`\n",
        "\n",
        "What does this represent? Here's one way to interpret it:\n",
        "* This model classifies animals as \"cat\" or \"dog\"\n",
        "* Our three inputs are height, weight, and age\n",
        "* Our ouputs represent \"probability of cat\" and \"probability of dog\"\n",
        "* Because this is a toy example, we aren't actually training the model here - just using randomly initialized weights! We will train later models in this notebook.\n",
        "\n",
        "Try filling in the blanks below and walking through each line! **If you want a hint or more details, check out the optional reference below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp-g9qotbRPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd12971-6275-40e1-84b7-6aa0007f3e92"
      },
      "source": [
        "# Fill in the blanks with your group!\n",
        "### YOUR CODE HERE:\n",
        "model_1 = Sequential()\n",
        "model_1.add(InputLayer(input_shape=(3,)))\n",
        "model_1.add(Dense(4, activation = 'relu'))\n",
        "model_1.add(Dense(2, activation = 'softmax'))\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer = 'adam', \n",
        "                metrics = ['accuracy'])\n",
        "model_1.predict([[14,18,5]]) #Try any input! This represents an animal of height 14, weight 18, and age 5.\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6218151 , 0.37818488]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWZ9zXtF2Cz"
      },
      "source": [
        "**Discuss:** How would you interpret this output? Does our (untrained) network classify this as a cat or a dog?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "781M4IyhssuA"
      },
      "source": [
        "####**Optional Reference**\n",
        "\n",
        "Here's some information about each step of the process. **You don't need to read through all this - check it as a reference if needed!**\n",
        "\n",
        "**1. Specify model**\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n",
        "\n",
        "\n",
        "**2. Add layers to the network**\n",
        "```\n",
        "model.add(Dense(4, activation = 'sigmoid'))\n",
        "```\n",
        "In this code, we add a layer of neurons to our network. \n",
        "\n",
        "This layer consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n",
        "\n",
        "We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'sigmoid'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers. \n",
        "\n",
        "```\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "```\n",
        "This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n",
        "\n",
        "**3. Turn the model on by compiling it** \n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'compile' it to prepare. We have to specify at the very least: a loss (how the model measures the quality of its weights), an optimizer (which adjusts the weights), and a metric (how to evaluate our results). Here are some common choices:\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer = 'adam',\n",
        "metrics = ['mean_squared_error'])\n",
        "  ```\n",
        "\n",
        "Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`. \n",
        "\n",
        "```\n",
        "model.fit(x, y)\n",
        "```\n",
        "\n",
        "To use the model, you can use it to predict something with:\n",
        "```\n",
        "y = model.predict(x)\n",
        "```\n",
        "\n",
        "You can actually use the model before you even train it! It just won't perform very well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YovNRgfuy0Oq"
      },
      "source": [
        "###(Optional) Exercise: Building a Multi-layer Neural Net Using Keras ✍️\n",
        "\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)\n",
        "\n",
        "Let's try another, bigger example!\n",
        "\n",
        "Here, we are predicting a house price: regression! Our inputs could be \"year the house was built\", \"home square footage\", and \"lot square footage\", while our output is price (in thousands of dollars).\n",
        "\n",
        "* Input Layer: 3 neurons\n",
        "\n",
        "* Layer 1: 4 neurons that are activated by `'relu' `and take in 3 inputs.\n",
        "\n",
        "* Layer 2: 4 neurons that are activated by `'relu'`\n",
        "\n",
        "* Layer 3 (out): 1 neuron that is activated by `'relu'`\n",
        "\n",
        "Compile the model with\n",
        "`'mean_squared_error'` as both loss and metric, and try making a prediction for some made-up data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm-ylEWqbXrQ"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(3,)))\n",
        "model.add(Dense(4, activation = 'relu'))\n",
        "model.add(Dense(4, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'relu'))\n",
        "model_1.compile(loss='mean_squared_error',\n",
        "                optimizer = 'adam', \n",
        "                metrics = ['accuracy'])\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVCmntRHRjPQ"
      },
      "source": [
        "###(Optional) Exercise: Dogs vs. Roads Using Keras\n",
        "\n",
        "Let's try an even bigger example! Here, we are going to distinguish between images of dogs and roads once again. \n",
        "\n",
        "* Input Layer: 3072 dimensions (32 pixels x 32 pixels x 3 color channels)\n",
        "\n",
        "* Layer 1: 32 neurons that are activated by `'relu' `and take in 3072 inputs.\n",
        "\n",
        "* Layer 2: 16 neurons that are activated by `'relu'`\n",
        "\n",
        "* Layer 3 (out): 2 neurons that is activated by `'sigmoid'`\n",
        "\n",
        "Compile the model with\n",
        "`loss = 'binary_crossentropy'`, and try making predictions on `inputs_train`!\n",
        "\n",
        "Once again, we are not actually training this model - so the predictions won't be any good. Soon we will create a CNN, which we will train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD2Dc4AYR31r"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbD6siv-Ip-"
      },
      "source": [
        "##Exercise: Building a CNN Using Keras! ✍️\n",
        "\n",
        "Now that we know how to build simple neural networks in Keras, let's build a CNN! The CNN will perform well on our data set of car and road images. \n",
        "\n",
        "Below is Keras code for a CNN. It will run as-is on the conscientious cars dataset. However, the performance is suboptimal. Add more layers and change the neural network hyperparameters so that the performance will be better. **Can you get the train and validation accuracy to both be higher than 95%?**\n",
        "\n",
        "The Keras core layer API may be a useful reference: https://keras.io/layers/core/ \n",
        "\n",
        "In particular and in addition to adding more of the existing convolutional layers and activations, consider using the following layers after a convolution + activation:\n",
        "\n",
        "`Dropout(N)`\n",
        "\n",
        "`MaxPooling2D(pool_size=(N, N))`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFVHyPKn-V4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c737933-0a36-4b14-f696-a1c7217b3452"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Reshape((32, 32, 3)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "###\n",
        "###\n",
        "### TODO: ADD MORE LAYERS HERE!!!!!\n",
        "\n",
        "model.add(Conv2D(64, (9, 9), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "###\n",
        "###\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN and plot accuracy.\n",
        "history = model.fit(inputs_train, labels_train, \\\n",
        "                    validation_data=(inputs_test, labels_test), \\\n",
        "                    epochs=70)\n",
        "plot_acc(history)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "30/30 [==============================] - 2s 15ms/step - loss: 13.0331 - accuracy: 0.6854 - val_loss: 1.0158 - val_accuracy: 0.8458\n",
            "Epoch 2/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.9937 - accuracy: 0.8604 - val_loss: 0.6324 - val_accuracy: 0.8625\n",
            "Epoch 3/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.8612 - accuracy: 0.8521 - val_loss: 0.3227 - val_accuracy: 0.9000\n",
            "Epoch 4/70\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.9021 - val_loss: 0.3108 - val_accuracy: 0.9250\n",
            "Epoch 5/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.9083 - val_loss: 0.2012 - val_accuracy: 0.9208\n",
            "Epoch 6/70\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.2929 - accuracy: 0.9156 - val_loss: 0.2454 - val_accuracy: 0.9375\n",
            "Epoch 7/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.9531 - val_loss: 0.5305 - val_accuracy: 0.8958\n",
            "Epoch 8/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2908 - accuracy: 0.9271 - val_loss: 0.3635 - val_accuracy: 0.9292\n",
            "Epoch 9/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 0.8849 - val_accuracy: 0.7833\n",
            "Epoch 10/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1879 - accuracy: 0.9531 - val_loss: 0.2582 - val_accuracy: 0.9458\n",
            "Epoch 11/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.9625 - val_loss: 0.1956 - val_accuracy: 0.9458\n",
            "Epoch 12/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1599 - accuracy: 0.9615 - val_loss: 0.1579 - val_accuracy: 0.9542\n",
            "Epoch 13/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 0.9240 - val_accuracy: 0.8500\n",
            "Epoch 14/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2704 - accuracy: 0.9583 - val_loss: 0.2092 - val_accuracy: 0.9500\n",
            "Epoch 15/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1470 - accuracy: 0.9760 - val_loss: 0.2333 - val_accuracy: 0.9417\n",
            "Epoch 16/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.5960 - val_accuracy: 0.8917\n",
            "Epoch 17/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9771 - val_loss: 0.3474 - val_accuracy: 0.9500\n",
            "Epoch 18/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9802 - val_loss: 0.2493 - val_accuracy: 0.9500\n",
            "Epoch 19/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.2046 - val_accuracy: 0.9458\n",
            "Epoch 20/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.9656 - val_loss: 0.2193 - val_accuracy: 0.9417\n",
            "Epoch 21/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.3560 - val_accuracy: 0.9250\n",
            "Epoch 22/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9937 - val_loss: 0.2034 - val_accuracy: 0.9458\n",
            "Epoch 23/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2095 - accuracy: 0.9802 - val_loss: 0.2805 - val_accuracy: 0.9542\n",
            "Epoch 24/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 0.3067 - val_accuracy: 0.9458\n",
            "Epoch 25/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9885 - val_loss: 2.4112 - val_accuracy: 0.7083\n",
            "Epoch 26/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9927 - val_loss: 0.2650 - val_accuracy: 0.9417\n",
            "Epoch 27/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.0353e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9542\n",
            "Epoch 28/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9802 - val_loss: 0.3260 - val_accuracy: 0.9542\n",
            "Epoch 29/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.9958 - val_loss: 0.4031 - val_accuracy: 0.9458\n",
            "Epoch 30/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0972 - accuracy: 0.9802 - val_loss: 0.2581 - val_accuracy: 0.9542\n",
            "Epoch 31/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.7710e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9542\n",
            "Epoch 32/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.0830e-04 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9500\n",
            "Epoch 33/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9927 - val_loss: 5.6790 - val_accuracy: 0.6667\n",
            "Epoch 34/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9865 - val_loss: 0.4396 - val_accuracy: 0.9500\n",
            "Epoch 35/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9958 - val_loss: 0.2614 - val_accuracy: 0.9542\n",
            "Epoch 36/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.3327e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9458\n",
            "Epoch 37/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 7.8692e-06 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9458\n",
            "Epoch 38/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 4.0208e-06 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9500\n",
            "Epoch 39/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.9698 - val_loss: 0.4001 - val_accuracy: 0.9625\n",
            "Epoch 40/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9969 - val_loss: 0.4627 - val_accuracy: 0.9542\n",
            "Epoch 41/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.1908e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9500\n",
            "Epoch 42/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.5401e-05 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9458\n",
            "Epoch 43/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 4.8949e-06 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9542\n",
            "Epoch 44/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.1040e-06 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.9458\n",
            "Epoch 45/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 4.6354e-07 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9500\n",
            "Epoch 46/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.9854 - val_loss: 0.2103 - val_accuracy: 0.9625\n",
            "Epoch 47/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.1860e-04 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9708\n",
            "Epoch 48/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 8.5859e-05 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9542\n",
            "Epoch 49/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 7.5821e-06 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9542\n",
            "Epoch 50/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.3494e-06 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9542\n",
            "Epoch 51/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 8.4884e-07 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9542\n",
            "Epoch 52/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9854 - val_loss: 0.4927 - val_accuracy: 0.9375\n",
            "Epoch 53/70\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.3616 - val_accuracy: 0.9625\n",
            "Epoch 54/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.9534e-05 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9542\n",
            "Epoch 55/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 9.4655e-06 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9500\n",
            "Epoch 56/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 9.3612e-07 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9500\n",
            "Epoch 57/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 4.5597e-07 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9500\n",
            "Epoch 58/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1953 - accuracy: 0.9854 - val_loss: 0.5390 - val_accuracy: 0.9417\n",
            "Epoch 59/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.6761 - val_accuracy: 0.9292\n",
            "Epoch 60/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 9.2686e-05 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.9375\n",
            "Epoch 61/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 7.9645e-06 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.9458\n",
            "Epoch 62/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.8993e-06 - accuracy: 1.0000 - val_loss: 0.6566 - val_accuracy: 0.9417\n",
            "Epoch 63/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.9854 - val_loss: 0.4207 - val_accuracy: 0.9500\n",
            "Epoch 64/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.8830e-05 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9500\n",
            "Epoch 65/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.4877e-06 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9542\n",
            "Epoch 66/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.4790e-06 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9542\n",
            "Epoch 67/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 7.4963e-07 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9542\n",
            "Epoch 68/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.3043e-07 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9542\n",
            "Epoch 69/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.4988e-07 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9583\n",
            "Epoch 70/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.9802 - val_loss: 0.4089 - val_accuracy: 0.9542\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JFLu0CdXM6K"
      },
      "source": [
        "**What interesting observations** do you make from the graph? How many epochs should you train for?\n",
        "\n",
        "We can also print out the structure of our model. What do the parts of the summary mean?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGwXs3C8YZl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a99c82db-382a-47d9-d014-40682421240f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_54 (Reshape)        (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_236 (Conv2D)         (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_346 (Activation)  (None, 32, 32, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_107 (MaxPooli  (None, 16, 16, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_237 (Conv2D)         (None, 16, 16, 64)        165952    \n",
            "                                                                 \n",
            " activation_347 (Activation)  (None, 16, 16, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_108 (MaxPooli  (None, 8, 8, 64)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_54 (Flatten)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_348 (Activation)  (None, 512)              0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 2)                 1026      \n",
            "                                                                 \n",
            " activation_349 (Activation)  (None, 2)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,265,538\n",
            "Trainable params: 2,265,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXINPAJvRr9W"
      },
      "source": [
        "#Advanced: Cats vs. Dogs With CNN\n",
        "\n",
        "So far, we've trained a CNN to distinguish between small images of cats and small images of dogs. It's more challenging and time-consuming to train CNNs for bigger images or harder tasks, like distinguishing dogs from cats (which look a lot more like dogs than roads do!)\n",
        "\n",
        "In this exercise, you'll adapt your previous model to classify large images of dogs vs. cats, and then try implementing a famous CNN architecture. Along the way, you'll deal with some of the debugging that machine learning engineers often have to handle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gU39z3jNMAt"
      },
      "source": [
        "#@title Run this to load cat and dog data. { display-mode: \"form\" }\n",
        "\n",
        "#Code here from https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=4PIP1rkmeAYS\n",
        "\n",
        "import tensorflow as tf\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  road_model = model\n",
        "  road_saved = True\n",
        "except NameError:\n",
        "  road_saved = False\n",
        "\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "train_image_generator      = ImageDataGenerator()  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator()  # Generator for our validation data\n",
        "train_data = train_image_generator.flow_from_directory(batch_size=2000,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                           class_mode='binary').next()\n",
        "val_data = validation_image_generator.flow_from_directory(batch_size=1000,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "\n",
        "                                                              class_mode='binary').next()\n",
        "cd_train_inputs, cd_train_labels = train_data\n",
        "cd_test_inputs, cd_test_labels = val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y5etOJwScaG"
      },
      "source": [
        "**Run the code below to see the dimensions of our training and validation data. What does each number mean? What is different than our previous dataset?** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjdedJ0VNvWg"
      },
      "source": [
        "print (cd_train_inputs.shape) \n",
        "print (cd_train_labels.shape) \n",
        "print (cd_test_inputs.shape) \n",
        "print (cd_test_labels.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIAkgOqWTAL7"
      },
      "source": [
        "**Run this code to see a random image from our training data (different each time).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HooiJ-RrQPcA"
      },
      "source": [
        "index = np.random.randint(len(cd_train_inputs))\n",
        "plt.imshow(cd_train_inputs[index]/255)\n",
        "plt.show()\n",
        "print(\"Label:\",cd_train_labels[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOwP9kX9UshH"
      },
      "source": [
        "**By adapting code from the previous exercise, build, train, and test a CNN to classify cats vs. dogs.**\n",
        "**Hints:**\n",
        "*   Use print(model.summary()) for a useful visualization of your model's architecture. Compare the summary of your cat/road and cat/dog classifiers.\n",
        "*  Substitute the names of the new datasets.\n",
        "*  Get a \"first try\" working by making small adjustments to a previous model before trying to optimize the accuracy. You can temporarily comment out layers as you figure things out.\n",
        "*  The outputs have different shapes betweeen the two datasets. What do you need to change? (You will get an ValueError that suggests how to transform the output to a one-hot encoding.) \n",
        "*  If you run out of memory, restart the notebook and/or use your knowledge of convolution arithmetic to reduce the size of an intermediate output (see [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)).\n",
        "* Dropout layers help reduce overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeuqlzigZZ8I"
      },
      "source": [
        "model = Sequential()\n",
        "#TODO: Your code here to build, train, and test a cats vs. dogs CNN!\n",
        "#If you run into errors, see the hints above for help debugging! \n",
        "#\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6sFSGEqjPwe"
      },
      "source": [
        "#Advanced Challenge: Implementing a Famous Architecture for Cats vs. Dogs\n",
        "\n",
        "Having trouble designing an effective architecture? Try implementing a version of AlexNet, one of the most famous CNNs for image convolution ever. You can find this image and other useful information on this network [here](https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96).\n",
        "\n",
        "![](https://lh4.googleusercontent.com/gFAxn9Z-Y1lgkNy2GfsqjXy1DvSuYF8rvP3CslRvmuoP5SUaJMrEOr24YShU_LwalLpYNJFwpJgcDh9whk9XrMOGQ1ADQ9FY_0saicCVH0jsNPDKOYBcTG4YhbqpbPolW4hZSdUsDQ)\n",
        "\n",
        "How do we read this diagram?\n",
        "\n",
        "On the left side, we start with images of dimension 227x227x3 (RGB). We apply a filter composed of 96 kernels of size 11x11, with stride size 4. We end up with data of dimension 55x55x96. We pass through multiple layers of convolution and max pooling as shown, before ending with three dense (fully connected) layers.\n",
        "\n",
        "Not shown: each layer uses ReLU activation, and we include dropout before the first two dense layers. Make sure to include those!\n",
        "\n",
        "You'll want to adjust some of these dimensions, for a few reasons: we're starting with 150x150 rather than 227x227 images, ending with 2 labels rather than 1000, and have limited data and memory. Use your knowledge of convolution arithmetic (see CNN slides) and the [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) to change the stride, kernel, and/or padding.\n",
        "\n",
        "Use model.summary() to understand the dimensions of your data at each step. To speed things up as you're building, you can set the number of epochs to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FHg8YTGtQ2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "bb08e222-12e9-4fb7-c865-aade39f1158b"
      },
      "source": [
        "model = Sequential()\n",
        "#TODO: Your code to run, train, and test AlexNet here:\n",
        "model.add(Conv2D(96, (11, 11), strides=4, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#model.add(Conv2D(256, (5, 5),padding='2'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bb4186ac71ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     self.strides = conv_utils.normalize_tuple(\n\u001b[1;32m    142\u001b[0m         strides, rank, 'strides', allow_zero=True)\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     self.dilation_rate = conv_utils.normalize_tuple(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36mnormalize_padding\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'causal'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     raise ValueError('The `padding` argument must be a list/tuple or one of '\n\u001b[0m\u001b[1;32m    222\u001b[0m                      \u001b[0;34m'\"valid\", \"same\" (or \"causal\", only for `Conv1D). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                      f'Received: {padding}')\n",
            "\u001b[0;31mValueError\u001b[0m: The `padding` argument must be a list/tuple or one of \"valid\", \"same\" (or \"causal\", only for `Conv1D). Received: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlF308hDjwyC"
      },
      "source": [
        "You might find that even AlexNet isn't working that well for you!\n",
        "\n",
        "This is because having a good architecture is only half the battle: AlexNet is a complex model designed to learn from millions of images. We're using a small dataset of only 2000 training images, so it's not surprising that our results aren't great. Our model is overfitting: essentially memorizing the few training images, rather than really learning the difference between a cat and a dog. (The advantage is that our model trains quickly.)\n",
        "\n",
        "To get really good performance, we need more data. If we can't find more, we could use *data augmentation*: inventing new training data by transforming our existing images. You can read more about it at https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVzEpI_xWpE5"
      },
      "source": [
        "![](https://images.pexels.com/photos/316/black-and-white-animal-dog-pet.jpg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)"
      ]
    }
  ]
}